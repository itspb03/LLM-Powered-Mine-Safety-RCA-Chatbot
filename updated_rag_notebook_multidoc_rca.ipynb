{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf2FbgDaVCa7"
      },
      "source": [
        "# Ollama PDF RAG Notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "6om3id_LVJvh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c30c9859-29a9-4af6-a189-565335b55672"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 41 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 697 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.12 [186 kB]\n",
            "Fetched 186 kB in 2s (117 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 121713 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.12_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.12) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.12) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m107.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m111.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.9/47.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.4/21.4 MB\u001b[0m \u001b[31m123.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m326.9/326.9 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m112.5/112.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m608.4/608.4 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m529.1/529.1 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.7/48.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m329.5/329.5 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m167.8/167.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.9/62.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-adk 1.19.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
            "google-adk 1.19.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n",
            "langgraph-prebuilt 1.0.5 requires langchain-core>=1.0.0, but you have langchain-core 0.3.29 which is incompatible.\n",
            "mcp 1.22.0 requires pydantic<3.0.0,>=2.11.0, but you have pydantic 2.9.2 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!apt-get install poppler-utils\n",
        "!pip install \\\n",
        "    langchain==0.3.14 \\\n",
        "    langchain-core==0.3.29 \\\n",
        "    langchain-ollama==0.2.2 \\\n",
        "    langchain_community==0.3.14 \\\n",
        "    langchain_text_splitters==0.3.5 \\\n",
        "    unstructured[all-docs] \\\n",
        "    pdfminer.six \\\n",
        "    pi_heif \\\n",
        "    unstructured_inference \\\n",
        "    pdf2image \\\n",
        "    chromadb \\\n",
        "    pydantic==2.9.2 \\\n",
        "    gradio -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOKtVqOlwUZ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bf76dd4-6de2-49c5-d20a-79361313e6cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdkgN6WKVCa9"
      },
      "source": [
        "## Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqKSphsQVCa9"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
        "from langchain_ollama import OllamaEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_ollama.chat_models import ChatOllama\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "from langchain_core.caches import BaseCache\n",
        "from langchain.cache import InMemoryCache # Import a concrete implementation of BaseCache\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Jupyter-specific imports\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Set environment variable for protobuf\n",
        "import os\n",
        "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze72jl1lVCa-"
      },
      "source": [
        "## Load PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReSf6OhNVCa-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35281345-d4ab-4e4d-cfd7-20a37e185fe7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No languages specified, defaulting to English.\n",
            "PDF loaded successfully: /content/drive/MyDrive/DGMS_Data/ma_1952.pdf\n",
            "Warning: No languages specified, defaulting to English.\n",
            "PDF loaded successfully: /content/drive/MyDrive/DGMS_Data/mmr.pdf\n",
            "Warning: No languages specified, defaulting to English.\n",
            "PDF loaded successfully: /content/drive/MyDrive/DGMS_Data/Coal Mines Regulation 2017.pdf\n",
            "Total documents loaded: 3\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# List all your PDF paths here\n",
        "pdf_paths = [\n",
        "    \"/content/drive/MyDrive/DGMS_Data/ma_1952.pdf\",\n",
        "    \"/content/drive/MyDrive/DGMS_Data/mmr.pdf\",\n",
        "    \"/content/drive/MyDrive/DGMS_Data/Coal Mines Regulation 2017.pdf\",\n",
        "    # add more paths as needed\n",
        "]\n",
        "\n",
        "docs = []\n",
        "for path in pdf_paths:\n",
        "    if path:\n",
        "        loader = UnstructuredPDFLoader(file_path=path)\n",
        "        pdf_docs = loader.load()\n",
        "        # Tag source so you can filter or inspect later if needed\n",
        "        for d in pdf_docs:\n",
        "            d.metadata[\"source_file\"] = path\n",
        "        docs.extend(pdf_docs)\n",
        "        print(f\"PDF loaded successfully: {path}\")\n",
        "    else:\n",
        "        print(\"Skipped an empty path.\")\n",
        "\n",
        "print(f\"Total documents loaded: {len(docs)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48wUwMQWVCa_"
      },
      "source": [
        "## Split text into chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dh9CsQ3RVCa_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df23906a-c33a-499a-8add-dae1396aee18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text split into 1290 chunks\n"
          ]
        }
      ],
      "source": [
        "# Split text into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "chunks = text_splitter.split_documents(docs)\n",
        "print(f\"Text split into {len(chunks)} chunks\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETUWGhKqsqoA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b66caba-1c62-4aed-8889-11697a7fe707"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Cleaning up old version at /usr/local/lib/ollama\n",
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "######################################################################## 100.0%\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n",
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\n",
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\n",
            "Ollama server and models are running.\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "\n",
        "\n",
        "# Start Ollama in the background\n",
        "serve_proc = subprocess.Popen(['ollama', 'serve'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "\n",
        "# Wait for Ollama to start (give it a few seconds)\n",
        "import time\n",
        "time.sleep(5)\n",
        "\n",
        "\n",
        "# Download the models you want to use\n",
        "!ollama pull nomic-embed-text\n",
        "!ollama pull llama3.2\n",
        "print(\"Ollama server and models are running.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9MFvnVkVCa_"
      },
      "source": [
        "## Create vector database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEf3yLUQVCbA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0030a9be-8e39-48b4-d37d-fda6d6232b1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector database created successfully\n"
          ]
        }
      ],
      "source": [
        "# Create vector database\n",
        "embedding = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
        "vector_db = Chroma.from_documents(\n",
        "    documents=chunks,\n",
        "    embedding=embedding,\n",
        "    collection_name=\"local-rag\",\n",
        ")\n",
        "print(\"Vector database created successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz4ZhYlIVCbA"
      },
      "source": [
        "## Set up LLM and Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJdQxlemVCbA"
      },
      "outputs": [],
      "source": [
        "# Set up LLM and retrieval\n",
        "local_model = \"llama3.2\"\n",
        "llm = ChatOllama(model=local_model)\n",
        "llm.model_rebuild()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKbmEYNjVCbA"
      },
      "outputs": [],
      "source": [
        "# Query prompt template\n",
        "QUERY_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"\"\"You are an AI language model assistant.\n",
        "    Use the following DGMS guidelines to answer the question and generate several focused search queries. If you don't know the answer based on the context, say so. Always cite the relevant section. gen\n",
        "    Original question: {question}\"\"\",\n",
        ")\n",
        "\n",
        "\n",
        "# Set up retriever\n",
        "retriever = MultiQueryRetriever.from_llm(\n",
        "    vector_db.as_retriever(),\n",
        "    llm,\n",
        "    prompt=QUERY_PROMPT\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToTEhNUQVCbA"
      },
      "source": [
        "## Create chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkol1i4rVCbB"
      },
      "outputs": [],
      "source": [
        "# RAG prompt template\n",
        "\n",
        "template = \"\"\"\n",
        "You are a mining safety and DGMS compliance expert.\n",
        "Use ONLY the DGMS context below to answer.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Task:\n",
        "1. First, classify the user question:\n",
        "   - If it is asking for a definition, meaning, scope, objectives, or main idea of an Act/Rule/Regulation (for example: 'define', 'what is', 'explain', 'main idea'), treat it as a DEFINITION question.\n",
        "   - If it describes an incident, accident, unsafe condition, non-compliance, or explicitly asks for 'cause', 'why', 'root cause', 'analysis', or 'recommendations', treat it as an INCIDENT / ROOT CAUSE question.\n",
        "   - If it mixes both, answer both, but keep root cause and recommendations strictly grounded in the context.\n",
        "\n",
        "2. For DEFINITION questions (only definition asked):\n",
        "   - First, check whether the provided DGMS / Mines Act context explicitly defines the term.\n",
        "     - If a definition is present (for example, in a definitions section like Section 2 of the Mines Act, 1952), quote that meaning in simple language and clearly mention the section number and clause (e.g. â€œSection 2(b) of the Mines Act, 1952 defines â€˜adultâ€™ as a person who has completed his eighteenth year.â€).\n",
        "     - Do NOT replace this statutory definition with a generic or approximate wording.\n",
        "   - Only if NO explicit definition or clause for the term is present in the context:\n",
        "     - State clearly: â€œThe provided DGMS/Mines Act context does not contain an explicit definition of â€˜<term>â€™.â€\n",
        "     - Then you may add a short, generic explanation like â€œIn general usage, an adult is a person who is 18 years of age or aboveâ€, but mark it as â€œgeneral understanding, not a formal definition from the provided textâ€.\n",
        "   - Never say that â€œno specific section defines <term>â€ if the context actually includes such a definition.\n",
        "   - Do NOT fabricate or assume incidents for pure definition questions.\n",
        "   - Do NOT perform root cause analysis or give recommendations unless the user has explicitly asked for causes or preventive measures.\n",
        "\n",
        "\n",
        "3. For INCIDENT / ROOT CAUSE questions:\n",
        "   - DGMS Explanation:\n",
        "     - Identify and briefly explain the relevant DGMS provisions from the context (with section or rule identifiers where available).\n",
        "   - Root Cause Analysis:\n",
        "     - Problem summary: Restate the incident / non-compliance in 2â€“3 sentences, using only what is in the question and context, without assuming extra details.\n",
        "     - Immediate causes: List the most likely direct causes supported by the context.\n",
        "     - Underlying causes: List deeper systemic causes (for example: organisation, procedure, training, supervision, maintenance, work environment) supported by the context.\n",
        "     - If the context does not specify a cause, clearly say \"Not specified in the provided DGMS context\" instead of guessing.\n",
        "   - Recommendations:\n",
        "     - ONLY provide recommendations if the user explicitly asks for \"recommendation\", \"prevent\", \"corrective action\", or \"what should be done\".\n",
        "     - When asked, give 3â€“5 specific, practical recommendations linked to relevant DGMS provisions from the context.\n",
        "     - If some recommendation is common-sense but not in the context, mark it as \"general good practice (not explicitly stated in the provided DGMS text)\".\n",
        "\n",
        "4. General constraints:\n",
        "   - Never invent Acts, section numbers, or accident scenarios that are not present in the context.\n",
        "   - If the Mines Act in the context is different from what the user seems to assume, explain only what is actually present in the context.\n",
        "   - If the answer cannot be derived from the context, clearly say so.\n",
        "\n",
        "Format the final answer as:\n",
        "\n",
        "DGMS Explanation\n",
        "- ...\n",
        "\n",
        "Root Cause Analysis (only if it is an INCIDENT / ROOT CAUSE question)\n",
        "- Problem summary: ...\n",
        "- Immediate causes: ...\n",
        "- Underlying causes: ...\n",
        "\n",
        "Recommendations (only if the user has asked for recommendations / corrective actions)\n",
        "- ...\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLBKGxC5VCbB"
      },
      "outputs": [],
      "source": [
        "# Create chain\n",
        "chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UTK6mdKVCbB"
      },
      "source": [
        "## Chat with PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dcXMZNbVCbB"
      },
      "outputs": [],
      "source": [
        "def chat_with_pdf(question):\n",
        "    \"\"\"\n",
        "    Chat with the PDF using the RAG chain.\n",
        "    \"\"\"\n",
        "    return display(Markdown(chain.invoke(question)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vkjy8-nnVCbB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "acd3f791-fb91-4bae-dda6-66d50744356f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "DGMS Explanation\n- The Mines Act, 1952 is an Act to amend and consolidate the law relating to the Regulation of labour and safety in mines.\n\nRecommendations \n- Ensure that all necessary measures are taken to eliminate or minimize risks to safety and health for persons employed in mines under control.\n- Conduct regular inspections and maintain records to ensure compliance with relevant provisions of the Mines Act, 1952.\n- Provide adequate training and supervision to employees working in mines."
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Example 1\n",
        "chat_with_pdf(\"What is the main idea of Mines Act?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdPwu-2OVCbB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "outputId": "23b8b4be-9357-4bbf-fe46-c96f75566717"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Section 2(b) of the Mines Act, 1952 defines â€˜adultâ€™ as a person who has completed his eighteenth year."
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Example 2\n",
        "chat_with_pdf(\"Define adult according to mines act?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YNsfrRxVCbB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "96d51550-5bf1-4f92-e562-ce3d445ba632"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "DGMS Explanation\n- Night shifts are governed by regulation 14(2)(b) of the Mines Act, 1952. This states that no work shall be carried on below ground in any mine except by a system of Shifts so arranged that the period of work for each shift is not spread-over more than the daily maximum hours stipulated.\n- The standard for night shifts as per the regulation is that if a person employed in a mine works on a shift which extends beyond midnight, then a weekly day of rest shall mean a period of twenty-four consecutive hours beginning when his shift ends (regulation 14(2)(a)).\n\nRecommendations\n- Ensure adequate lighting during all periods of work, including night shifts.\n- Implement and enforce the daily maximum hours for night shifts as per regulation 14(2) to prevent overwork and ensure rest time is provided.\n- Provide adequate supervision and control during night shifts to secure safe operation."
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Example 3\n",
        "chat_with_pdf(\"Describe regulations for night shifts?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "EDCVmOEz7awc",
        "outputId": "c02184ee-b864-41c9-b8f3-f4d5a43f0a0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://8a1528c7fa9e2ccc48.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8a1528c7fa9e2ccc48.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://8a1528c7fa9e2ccc48.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def respond_to_query(message, history):\n",
        "    if not message.strip():\n",
        "        return \"Please enter a valid question.\"\n",
        "    try:\n",
        "        response = chain.invoke({\"question\": message})\n",
        "        return response if response and response.strip() else \"No answer found for your query.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error processing query: {str(e)}\"\n",
        "\n",
        "\n",
        "# Custom theme tweaking textbox and button colors only via theme API\n",
        "custom_theme = gr.themes.Soft(\n",
        "    primary_hue=\"indigo\",\n",
        "    neutral_hue=\"slate\",\n",
        "    font=[gr.themes.GoogleFont(\"Verdana\"), \"Verdana\", \"sans-serif\"],\n",
        ").set(\n",
        "    # Textbox background and border color\n",
        "    body_background_fill=\"#ffffff\",\n",
        "    input_background_fill=\"#f7f9ff\",\n",
        "    input_border_color=\"#ffffff\",\n",
        "    # Button colors\n",
        "    button_secondary_background_fill=\"#ffffff\",\n",
        "    button_secondary_background_fill_hover=\"#f7f9ff\",\n",
        "    button_secondary_border_color=\"#ffffff\",\n",
        "    button_secondary_text_color=\"#ffffff\",\n",
        ")\n",
        "\n",
        "with gr.Blocks(theme=custom_theme) as demo:\n",
        "    gr.Markdown(\"# ğŸ“„ Mining Safety Q&A\")\n",
        "\n",
        "    chatbot = gr.Chatbot(\n",
        "        height=500,\n",
        "        label=\"Chat History\",\n",
        "        show_copy_button=True\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        msg = gr.Textbox(\n",
        "            label=\"Your Question\",\n",
        "            placeholder=\"Ask anything..\",\n",
        "            scale=4,\n",
        "        )\n",
        "        submit_btn = gr.Button(\n",
        "            \"Send\",\n",
        "            scale=1,\n",
        "            variant=\"secondary\",  # lighter, bordered look\n",
        "        )\n",
        "\n",
        "    with gr.Row():\n",
        "        clear_btn = gr.Button(\n",
        "            \"Clear Chat\",\n",
        "            variant=\"secondary\",\n",
        "            size=\"sm\",\n",
        "        )\n",
        "\n",
        "    gr.Examples(\n",
        "        examples=[\n",
        "            \"Write in brief about Mines Act?\",\n",
        "            \"What are the safety regulations in CMR?\",\n",
        "            \"What are the ventilation requirements in MMR?\",\n",
        "            \"Date - 04.09.16 Mine - RAVINDRA KHANI NO.5 Time - 1.45 Owner - Singareni Collieries Company Ltd. Dist. - Adilabad, State - Telangana Person(s) Killed :  1. Badri Janardhan,Supportman, Male, 54YearsWhile a group of five persons were erecting cog in an underground depillaring panelof a coal mine after withdrawing supports from goaf edge, all of a sudden a mass ofresin bolted coarse grained sandstone roof measuring about 13.2m (length) x 1.6m to4.4m (width) x 0.35m to 1.5m(height) fell from height of about 1.60m on twopersons, completely burying them; one person died instantaneously, another rescuedwith serious injuries after about 4 hrs and three persons escaped unhurt. The area had shown signs of deteriorating ground conditions earlier in the shift, including audible popping sounds and small rock fragments falling from the roof. The on-shift supervisor had been informed but allowed work to continue, stating the section needed to stay on schedule. No additional support, such as temporary props or supplemental bolts, was installed prior to the failure.?\"\n",
        "        ],\n",
        "        inputs=msg\n",
        "    )\n",
        "\n",
        "    def user_message(user_input, chat_history):\n",
        "        if not user_input.strip():\n",
        "            return \"\", chat_history\n",
        "        return \"\", chat_history + [[user_input, None]]\n",
        "\n",
        "    def bot_response(chat_history):\n",
        "        user_input = chat_history[-1][0]\n",
        "        bot_reply = respond_to_query(user_input, chat_history)\n",
        "        chat_history[-1][1] = bot_reply\n",
        "        return chat_history\n",
        "\n",
        "    msg.submit(user_message, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
        "        bot_response, chatbot, chatbot\n",
        "    )\n",
        "    submit_btn.click(user_message, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
        "        bot_response, chatbot, chatbot\n",
        "    )\n",
        "    clear_btn.click(lambda: [], None, chatbot, queue=False)\n",
        "\n",
        "demo.launch(share=True, debug=True, max_threads=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt1yrsPpVCbC"
      },
      "source": [
        "## Clean up (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ue3Wx_U4VCbC"
      },
      "outputs": [],
      "source": [
        "# Optional: Clean up when done\n",
        "vector_db.delete_collection()\n",
        "print(\"Vector database deleted successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e282Zx136hft"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}